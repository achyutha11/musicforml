{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64d15b64-ee5f-4858-af48-af459c3fbd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattening complete. MIDI files are now in './maestro_flat'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "source_dir = './maestro-v2.0.0'  # Replace with the actual path if needed\n",
    "destination_dir = './maestro_flat' # Directory to store flattened files\n",
    "\n",
    "# Create the destination directory if it doesn't exist\n",
    "if not os.path.exists(destination_dir):\n",
    "    os.makedirs(destination_dir)\n",
    "\n",
    "# Walk through the source directory\n",
    "for root, _, files in os.walk(source_dir):\n",
    "    for file in files:\n",
    "        # Check if the file is a MIDI file\n",
    "        if file.endswith('.midi') or file.endswith('.mid'):\n",
    "            source_path = os.path.join(root, file)\n",
    "            destination_path = os.path.join(destination_dir, file)\n",
    "            # Move the file\n",
    "            shutil.move(source_path, destination_path)\n",
    "\n",
    "print(f\"Flattening complete. MIDI files are now in '{destination_dir}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "272b230d-97fe-4473-ad00-c12d9a43a715",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/opt/conda/lib/python3.11/runpy.py\", line 198, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.11/runpy.py\", line 88, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/aboomina/task3kernel/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/aboomina/task3kernel/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/aboomina/task3kernel/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/aboomina/task3kernel/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/aboomina/task3kernel/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/aboomina/task3kernel/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/aboomina/task3kernel/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/aboomina/task3kernel/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/home/aboomina/task3kernel/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/aboomina/task3kernel/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/aboomina/task3kernel/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/aboomina/task3kernel/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3098, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/aboomina/task3kernel/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3153, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/home/aboomina/task3kernel/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/aboomina/task3kernel/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3365, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/aboomina/task3kernel/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3610, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/aboomina/task3kernel/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3670, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_226/84624043.py\", line 5, in <module>\n",
      "    import torchaudio\n",
      "  File \"/home/aboomina/task3kernel/lib/python3.11/site-packages/torchaudio/__init__.py\", line 1, in <module>\n",
      "    from torchaudio import (  # noqa: F401\n",
      "  File \"/home/aboomina/task3kernel/lib/python3.11/site-packages/torchaudio/compliance/__init__.py\", line 1, in <module>\n",
      "    from . import kaldi\n",
      "  File \"/home/aboomina/task3kernel/lib/python3.11/site-packages/torchaudio/compliance/kaldi.py\", line 22, in <module>\n",
      "    EPSILON = torch.tensor(torch.finfo(torch.float).eps)\n",
      "/home/aboomina/task3kernel/lib/python3.11/site-packages/torchaudio/compliance/kaldi.py:22: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  EPSILON = torch.tensor(torch.finfo(torch.float).eps)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import torchaudio.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f7df695-4bdb-425f-b427-250a37b96c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIDI_DIR = \"./maestro_flat/\"\n",
    "SEQ_LEN = 512\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 10\n",
    "EMBED_DIM = 512\n",
    "NUM_HEADS = 8\n",
    "NUM_LAYERS = 6\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "TOKENIZER_DIR = \"./tokenizer_config/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48b194b0-ceec-4dd6-8740-93cd86b6ab0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aboomina/task3kernel/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from miditok import REMI\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04cd1684-9291-44f5-9f4c-317a5acfcabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_226/3206696221.py:2: UserWarning: miditok: The `save_params` method had been renamed `save`. It is now depreciated and will be removed in future updates.\n",
      "  tokenizer.save_params(Path(TOKENIZER_DIR))  # Save tokenizer config\n",
      "/tmp/ipykernel_226/3206696221.py:8: UserWarning: miditok: The `midi_to_tokens` method had been renamed `encode`. It is now depreciated and will be removed in future updates.\n",
      "  tokens = tokenizer.midi_to_tokens(Path(MIDI_DIR) / file)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = REMI()\n",
    "tokenizer.save_params(Path(TOKENIZER_DIR))  # Save tokenizer config\n",
    "\n",
    "# Tokenize all MIDI files\n",
    "token_sequences = []\n",
    "for file in os.listdir(MIDI_DIR):\n",
    "    if file.endswith(\".mid\") or file.endswith(\".midi\"):\n",
    "        tokens = tokenizer.midi_to_tokens(Path(MIDI_DIR) / file)\n",
    "        token_ids = tokens[0].ids\n",
    "        \n",
    "        if len(token_ids) >= SEQ_LEN:\n",
    "            token_sequences.append(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "880cb4be-1dde-4bb9-a046-9d73e96423a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MidiDataset(Dataset):\n",
    "    def __init__(self, sequences, seq_len):\n",
    "        self.data = []\n",
    "        for seq in sequences:\n",
    "            for i in range(0, len(seq) - seq_len, seq_len):\n",
    "                chunk = seq[i:i+seq_len]\n",
    "                self.data.append(chunk)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.data[idx][:-1], dtype=torch.long)\n",
    "        y = torch.tensor(self.data[idx][1:], dtype=torch.long)\n",
    "        return x, y\n",
    "\n",
    "dataset = MidiDataset(token_sequences, SEQ_LEN)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad93507d-44f0-44e6-b8de-369498486cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MidiTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads, num_layers):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.pos_emb = nn.Parameter(torch.zeros(1, SEQ_LEN - 1, embed_dim))\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model=embed_dim, nhead=num_heads)\n",
    "        self.transformer = nn.TransformerDecoder(decoder_layer, num_layers)\n",
    "        self.fc_out = nn.Linear(embed_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len)\n",
    "        x = self.token_emb(x) + self.pos_emb[:, :x.size(1), :]\n",
    "        x = x.permute(1, 0, 2)  # (seq_len, batch, embed_dim)\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(x.size(0)).to(x.device)\n",
    "        out = self.transformer(x, x, tgt_mask=tgt_mask)\n",
    "        out = self.fc_out(out)\n",
    "        return out.permute(1, 0, 2)  # (batch, seq_len, vocab)\n",
    "\n",
    "# --------- Training ---------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d47246-d223-4c0b-9a83-7d29da4f47a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MidiTransformer(vocab_size=len(tokenizer), embed_dim=EMBED_DIM,\n",
    "                        num_heads=NUM_HEADS, num_layers=NUM_LAYERS).to(DEVICE)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"Training on {DEVICE}...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch in tqdm(dataloader):\n",
    "        x, y = batch\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = criterion(output.reshape(-1, output.size(-1)), y.reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {epoch_loss/len(dataloader):.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(), \"midi_transformer.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47d68854-d49e-4ea4-af96-5001ca365ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MidiTransformer(\n",
       "  (token_emb): Embedding(282, 512)\n",
       "  (transformer): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc_out): Linear(in_features=512, out_features=282, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MidiTransformer(vocab_size=len(tokenizer), embed_dim=EMBED_DIM,\n",
    "                        num_heads=NUM_HEADS, num_layers=NUM_LAYERS).to(DEVICE)\n",
    "model.load_state_dict(torch.load(\"midi_transformer.pth\", map_location=DEVICE))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20365bb5-7873-4841-a320-f3846976a6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_226/3501021188.py:9: UserWarning: miditok: The `midi_to_tokens` method had been renamed `encode`. It is now depreciated and will be removed in future updates.\n",
      "  tokenized_midi = tokenizer.midi_to_tokens(\"maestro_flat/seed1.midi\")[0]  # Only use the first track\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 206, 26, 110, 135, 215, 33, 112, 131, 4, 189, 41, 113, 126, 194, 41, 114, 127, 197, 33, 113, 128, 200, 26, 113, 126, 204, 26, 111, 130, 208, 33]\n",
      "TokSequence(tokens=[], ids=[4, 206, 26, 110, 135, 215, 33, 112, 131, 4, 189, 41, 113, 126, 194, 41, 114, 127, 197, 33, 113, 128, 200, 26, 113, 126, 204, 26, 111, 130, 208, 33, 113, 126, 200, 26, 111, 130, 208, 26, 113, 126, 200, 26, 111, 130, 208, 26, 113, 126, 200, 26, 111, 130, 208, 26, 113, 126, 200, 26, 111, 130, 208, 26, 113, 126, 200, 26, 111, 130, 208, 26, 113, 126, 200, 26, 111, 130, 208, 26, 113, 126, 200, 26, 111, 130, 208, 26, 113, 126, 200, 26, 111, 130, 208, 26, 113, 126, 200, 26, 111, 130, 208, 26, 113, 126, 208, 26, 111, 130, 200, 26, 113, 126, 208, 26, 111, 130, 208, 26, 113, 126, 208, 26, 111, 126, 208, 26, 113, 130, 208, 26, 111, 126, 208, 26, 113, 126, 208, 26, 111, 126, 208, 26, 113, 126, 208, 26, 111, 126, 208, 26, 113, 126, 208, 26, 111, 126, 208, 26, 113, 208, 208, 208, 208, 26, 111, 126, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208], bytes='', events=[], are_ids_encoded=False, _ticks_bars=[], _ticks_beats=[], _ids_decoded=[])\n",
      "<class 'miditok.classes.TokSequence'>\n",
      "TokSequence(tokens=['Bar_None', 'Position_17', 'Pitch_42', 'Velocity_71', 'Duration_1.3.8', 'Position_26', 'Pitch_49', 'Velocity_79', 'Duration_0.7.8', 'Bar_None', 'Position_0', 'Pitch_57', 'Velocity_83', 'Duration_0.2.8', 'Position_5', 'Pitch_57', 'Velocity_87', 'Duration_0.3.8', 'Position_8', 'Pitch_49', 'Velocity_83', 'Duration_0.4.8', 'Position_11', 'Pitch_42', 'Velocity_83', 'Duration_0.2.8', 'Position_15', 'Pitch_42', 'Velocity_75', 'Duration_0.6.8', 'Position_19', 'Pitch_49', 'Velocity_83', 'Duration_0.2.8', 'Position_11', 'Pitch_42', 'Velocity_75', 'Duration_0.6.8', 'Position_19', 'Pitch_42', 'Velocity_83', 'Duration_0.2.8', 'Position_11', 'Pitch_42', 'Velocity_75', 'Duration_0.6.8', 'Position_19', 'Pitch_42', 'Velocity_83', 'Duration_0.2.8', 'Position_11', 'Pitch_42', 'Velocity_75', 'Duration_0.6.8', 'Position_19', 'Pitch_42', 'Velocity_83', 'Duration_0.2.8', 'Position_11', 'Pitch_42', 'Velocity_75', 'Duration_0.6.8', 'Position_19', 'Pitch_42', 'Velocity_83', 'Duration_0.2.8', 'Position_11', 'Pitch_42', 'Velocity_75', 'Duration_0.6.8', 'Position_19', 'Pitch_42', 'Velocity_83', 'Duration_0.2.8', 'Position_11', 'Pitch_42', 'Velocity_75', 'Duration_0.6.8', 'Position_19', 'Pitch_42', 'Velocity_83', 'Duration_0.2.8', 'Position_11', 'Pitch_42', 'Velocity_75', 'Duration_0.6.8', 'Position_19', 'Pitch_42', 'Velocity_83', 'Duration_0.2.8', 'Position_11', 'Pitch_42', 'Velocity_75', 'Duration_0.6.8', 'Position_19', 'Pitch_42', 'Velocity_83', 'Duration_0.2.8', 'Position_11', 'Pitch_42', 'Velocity_75', 'Duration_0.6.8', 'Position_19', 'Pitch_42', 'Velocity_83', 'Duration_0.2.8', 'Position_19', 'Pitch_42', 'Velocity_75', 'Duration_0.6.8', 'Position_11', 'Pitch_42', 'Velocity_83', 'Duration_0.2.8', 'Position_19', 'Pitch_42', 'Velocity_75', 'Duration_0.6.8', 'Position_19', 'Pitch_42', 'Velocity_83', 'Duration_0.2.8', 'Position_19', 'Pitch_42', 'Velocity_75', 'Duration_0.2.8', 'Position_19', 'Pitch_42', 'Velocity_83', 'Duration_0.6.8', 'Position_19', 'Pitch_42', 'Velocity_75', 'Duration_0.2.8', 'Position_19', 'Pitch_42', 'Velocity_83', 'Duration_0.2.8', 'Position_19', 'Pitch_42', 'Velocity_75', 'Duration_0.2.8', 'Position_19', 'Pitch_42', 'Velocity_83', 'Duration_0.2.8', 'Position_19', 'Pitch_42', 'Velocity_75', 'Duration_0.2.8', 'Position_19', 'Pitch_42', 'Velocity_83', 'Duration_0.2.8', 'Position_19', 'Pitch_42', 'Velocity_75', 'Duration_0.2.8', 'Position_19', 'Pitch_42', 'Velocity_83', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Pitch_42', 'Velocity_75', 'Duration_0.2.8', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19', 'Position_19'], ids=[4, 206, 26, 110, 135, 215, 33, 112, 131, 4, 189, 41, 113, 126, 194, 41, 114, 127, 197, 33, 113, 128, 200, 26, 113, 126, 204, 26, 111, 130, 208, 33, 113, 126, 200, 26, 111, 130, 208, 26, 113, 126, 200, 26, 111, 130, 208, 26, 113, 126, 200, 26, 111, 130, 208, 26, 113, 126, 200, 26, 111, 130, 208, 26, 113, 126, 200, 26, 111, 130, 208, 26, 113, 126, 200, 26, 111, 130, 208, 26, 113, 126, 200, 26, 111, 130, 208, 26, 113, 126, 200, 26, 111, 130, 208, 26, 113, 126, 200, 26, 111, 130, 208, 26, 113, 126, 208, 26, 111, 130, 200, 26, 113, 126, 208, 26, 111, 130, 208, 26, 113, 126, 208, 26, 111, 126, 208, 26, 113, 130, 208, 26, 111, 126, 208, 26, 113, 126, 208, 26, 111, 126, 208, 26, 113, 126, 208, 26, 111, 126, 208, 26, 113, 126, 208, 26, 111, 126, 208, 26, 113, 208, 208, 208, 208, 26, 111, 126, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208], bytes='', events=[], are_ids_encoded=False, _ticks_bars=[], _ticks_beats=[], _ids_decoded=[])\n",
      "<class 'miditok.classes.TokSequence'>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "File not found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Convert to MIDI\u001b[39;00m\n\u001b[32m     34\u001b[39m pls = Path(\u001b[33m\"\u001b[39m\u001b[33mnew\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprograms\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnew\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/task3kernel/lib/python3.11/site-packages/miditok/midi_tokenizer.py:1975\u001b[39m, in \u001b[36mMusicTokenizer.decode\u001b[39m\u001b[34m(self, tokens, programs, output_path)\u001b[39m\n\u001b[32m   1973\u001b[39m         score.dump_abc(output_path)\n\u001b[32m   1974\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1975\u001b[39m         \u001b[43mscore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump_midi\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1976\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "\u001b[31mRuntimeError\u001b[39m: File not found"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from miditok import REMI, TokSequence\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = REMI(params=Path(\"tokenizer_config/tokenizer.json\"))\n",
    "\n",
    "# Tokenize MIDI file\n",
    "tokenized_midi = tokenizer.midi_to_tokens(\"maestro_flat/seed1.midi\")[0]  # Only use the first track\n",
    "\n",
    "# Take the first N tokens as seed (e.g., 32)\n",
    "generated = tokenized_midi.ids[:32]\n",
    "print(generated)\n",
    "\n",
    "# Define your constants (replace with actual values)\n",
    "for _ in range(SEQ_LEN):\n",
    "    input_seq = torch.tensor(generated[-(SEQ_LEN - 1):], dtype=torch.long).unsqueeze(0).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_seq)\n",
    "    next_token = torch.argmax(output[0, -1], dim=-1).item()\n",
    "    generated.append(next_token)\n",
    "\n",
    "# Convert Tokens to MIDI\n",
    "sequence = TokSequence(ids=generated)\n",
    "print(sequence)\n",
    "print(type(sequence))\n",
    "\n",
    "# Complete missing token info (like strings)\n",
    "tokenizer.complete_sequence(sequence)\n",
    "print(sequence)\n",
    "print(type(sequence))\n",
    "\n",
    "# Convert to MIDI\n",
    "pls = Path(\"new\")\n",
    "tokenizer.decode(tokens=[sequence], programs=None, output_path=Path(\"new\"))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116cbb88-c6a3-4303-86c7-54fb07e5e2ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "task3kernel",
   "language": "python",
   "name": "task3kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
